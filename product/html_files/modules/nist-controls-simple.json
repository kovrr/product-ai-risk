{
  "framework": "NIST AI RMF",
  "controls": [
    {"id": "GOVERN 1.1", "title": "Legal and regulatory requirements involving AI are understood, managed, and documented"},
    {"id": "GOVERN 1.2", "title": "Roles and responsibilities for AI systems are documented and assigned"},
    {"id": "GOVERN 1.3", "title": "Organizational AI risk culture reflects values and AI risk management principles"},
    {"id": "GOVERN 1.4", "title": "Diversity, equity, inclusion, and accessibility processes are prioritized"},
    {"id": "GOVERN 1.5", "title": "Organizational policies address AI risks and benefits"},
    {"id": "GOVERN 1.6", "title": "Mechanisms are in place to inventory AI systems and track AI risks"},
    {"id": "GOVERN 2.1", "title": "Roles and responsibilities are defined for testing and monitoring AI systems"},
    {"id": "GOVERN 2.2", "title": "Accountability structures are in place to ensure responsible use of AI"},
    {"id": "GOVERN 3.1", "title": "Risk management processes for AI are integrated into organizational practices"},
    {"id": "GOVERN 4.1", "title": "Organizational teams are equipped with necessary skills and resources"},
    {"id": "MAP 1.1", "title": "Context about systems, tasks, and intended use is understood and documented"},
    {"id": "MAP 1.2", "title": "Categorization of AI systems based on impact levels is performed"},
    {"id": "MAP 2.1", "title": "Data inputs and training datasets are understood, inventoried, and documented"},
    {"id": "MAP 2.2", "title": "Data and model provenance is understood and documented"},
    {"id": "MAP 3.1", "title": "Threats, vulnerabilities, and potential impacts are identified and documented"},
    {"id": "MEASURE 1.1", "title": "Approaches and metrics for measuring AI risks are defined and implemented"},
    {"id": "MEASURE 2.1", "title": "AI system trustworthiness characteristics are measured and evaluated"},
    {"id": "MEASURE 2.2", "title": "AI system accuracy, precision, recall, and F1 score are measured"},
    {"id": "MEASURE 2.3", "title": "Privacy risks and data protection measures are assessed"},
    {"id": "MEASURE 2.7", "title": "AI system failures and errors are tracked and analyzed"},
    {"id": "MEASURE 2.11", "title": "Fairness and bias metrics are measured and evaluated"},
    {"id": "MEASURE 3.1", "title": "Internal testing approaches are established and tracked over time"},
    {"id": "MEASURE 4.2", "title": "Feedback from users and stakeholders is gathered and assessed"},
    {"id": "MANAGE 1.1", "title": "AI risks are prioritized based on impact, likelihood, and available resources"},
    {"id": "MANAGE 1.2", "title": "AI risk treatment and response plans are developed and implemented"},
    {"id": "MANAGE 2.1", "title": "Resources for AI risk management are allocated and monitored"},
    {"id": "MANAGE 2.3", "title": "Mechanisms for continuous monitoring of AI systems are in place"},
    {"id": "MANAGE 3.1", "title": "AI system outputs and impacts are continuously monitored"},
    {"id": "MANAGE 4.1", "title": "Incidents related to AI systems are tracked, documented, and managed"}
  ]
}
