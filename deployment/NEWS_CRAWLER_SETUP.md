# News Crawler Setup & Deployment

## Overview

The AIKovrr platform uses Playwright headless browser to crawl AI governance news from:
1. **IAPP** (International Association of Privacy Professionals)
2. **Compliance Week**

## ‚úÖ What Was Fixed

### Issue
- Playwright browsers were installed on Mac (development) but deployed to Linux (production)
- Mac browsers (`chrome-mac`) don't work on Linux servers
- Crawlers failed with: `Executable doesn't exist at chrome-linux/headless_shell`

### Solution
1. **Updated deployment script** (`deploy_to_gcloud.sh`):
   - Added Step 7.5: Install Playwright browsers for Linux
   - Removes Mac-based browsers: `rm -rf ~/.cache/ms-playwright`
   - Installs Linux browsers: `playwright install chromium`
   - Installs system dependencies: `playwright install-deps chromium`
   - Runs crawlers automatically during deployment

2. **Created helper scripts**:
   - `install_playwright_browsers.sh` - Install browsers on server
   - `run_crawlers_on_server.sh` - Run crawlers manually
   - `test_crawler_connectivity.py` - Test internet connectivity

## üìã Deployment Process

### Automatic (Recommended)

When you run `./deployment/deploy.sh`, the deployment script now:
1. Installs Playwright and dependencies
2. Removes any Mac browsers
3. Installs Linux browsers
4. Runs both crawlers to fetch initial news (10 articles each)

### Manual (If Needed)

If you need to run crawlers manually on the server:

```bash
# SSH into server
gcloud compute ssh platform --zone us-central1-f --tunnel-through-iap

# Navigate to backend
cd /opt/aikovrr/backend
source venv/bin/activate

# Run IAPP crawler
python manage.py fetch_iapp_news --max-articles 10

# Run Compliance Week crawler
python manage.py fetch_compliance_week_news --max-articles 10

# Check results
python manage.py shell
>>> from news.models import NewsArticle
>>> NewsArticle.objects.count()
>>> for article in NewsArticle.objects.all()[:5]:
...     print(f'{article.source}: {article.title}')
```

## üîß Troubleshooting

### Issue: "Executable doesn't exist"
```bash
# Reinstall browsers on server
cd /opt/aikovrr/backend
source venv/bin/activate
rm -rf ~/.cache/ms-playwright
playwright install chromium
```

### Issue: "No module named 'playwright'"
```bash
# Install Playwright
cd /opt/aikovrr/backend
source venv/bin/activate
pip install playwright beautifulsoup4
playwright install chromium
```

### Issue: Crawlers timeout or fail
```bash
# Test internet connectivity
cd /opt/aikovrr/backend
source venv/bin/activate
python test_crawler_connectivity.py
```

**Common causes:**
- Firewall blocking outbound HTTPS (ports 80, 443)
- DNS resolution issues
- Server cannot access external websites

## üìä Crawler Details

### IAPP Crawler
- **Command**: `python manage.py fetch_iapp_news --max-articles 10`
- **URL**: https://iapp.org/news/
- **Filters**: AI governance keywords (ai governance, ai risk, eu ai act, etc.)
- **Output**: Saves to `news_newsarticle` table

### Compliance Week Crawler
- **Command**: `python manage.py fetch_compliance_week_news --max-articles 10`
- **URL**: https://www.complianceweek.com/news/ai
- **Filters**: AI governance keywords
- **Output**: Saves to `news_newsarticle` table

## üîÑ Scheduled Updates (CONFIGURED ‚úÖ)

**Status**: Daily cron job is configured and running on the server.

### Setup

Run the setup script from your local machine:
```bash
./deployment/setup_daily_news_cron.sh
```

This installs a cron job that:
- Runs daily at 6:00 AM (UTC)
- Fetches up to 20 articles from IAPP
- Attempts to fetch from Compliance Week (may fail due to site restrictions)
- Logs all activity to `/opt/aikovrr/backend/logs/news_crawler_YYYYMMDD.log`
- Keeps last 7 days of logs

### Manual Test

```bash
# Test the cron script
gcloud compute ssh platform --zone us-central1-f --tunnel-through-iap --command '/opt/aikovrr/backend/fetch_news.sh'

# View logs
gcloud compute ssh platform --zone us-central1-f --tunnel-through-iap --command 'cat /opt/aikovrr/backend/logs/news_crawler_*.log'
```

### Current Status

- ‚úÖ **IAPP Crawler**: Working - Successfully fetches 1-3 new articles daily
- ‚ö†Ô∏è **Compliance Week Crawler**: Limited - Site may block automated access
  - Fallback: Manual articles seeded in database
  - Alternative: Use RSS feed or API if available

## üìÅ Files Modified

1. **`/deployment/deploy_to_gcloud.sh`**
   - Added Step 7.5: Install Playwright browsers
   - Added Step 10.5: Run news crawlers

2. **Created Scripts**:
   - `/deployment/install_playwright_browsers.sh`
   - `/deployment/run_crawlers_on_server.sh`
   - `/backend/test_crawler_connectivity.py`

## ‚úÖ Verification

After deployment, verify crawlers work:

```bash
# From local machine
./deployment/run_crawlers_on_server.sh

# Expected output:
# ‚úÖ IAPP page loaded successfully
# ‚úÖ Found ~16 article links
# ‚úÖ Compliance Week page loaded successfully
# ‚úÖ Found ~30 article links
# Total articles in database: 20+
```

## üåê View Results

After crawlers run, news articles appear in:
- **Dashboard**: Compliance News Feed widget (auto-scrolling)
- **Django Admin**: http://136.113.138.156:8000/admin/news/newsarticle/
- **API**: http://136.113.138.156:8000/api/news/articles/

---

## üìä Test Results (December 1, 2025)

### ‚úÖ IAPP Crawler - WORKING
```
Latest test run:
- Articles found: 16
- New articles added: 2
- Duplicates skipped: 5
- Non-AI skipped: 9
- Total in DB: 23
- Status: SUCCESS ‚úÖ
```

### ‚ö†Ô∏è Compliance Week Crawler - LIMITED
```
Latest test run:
- Articles found: 0
- Issue: Site may block automated browsers
- Fallback: 5 articles seeded in database
- Status: PARTIAL (relies on seed data)
```

### üéØ Overall Status
- **News Feed**: ‚úÖ Operational with 23 articles
- **Daily Updates**: ‚úÖ Cron job configured (6 AM UTC)
- **IAPP**: ‚úÖ Fetches 1-3 new articles daily
- **Compliance Week**: ‚ö†Ô∏è Uses seed data, crawler blocked

---

**Last Updated**: December 1, 2025  
**Status**: ‚úÖ Working on production server  
**Daily Cron**: ‚úÖ Configured and tested
